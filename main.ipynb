{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaLHjbgl4sdC"
   },
   "source": [
    "# Computer Vision (Image operators and filters)\n",
    "\n",
    "By the end of this lab, you will get hands on experience working with:\n",
    "\n",
    "*   Image Handling\n",
    "*   Image Manipulation\n",
    "*   Histogram and Histogram Equalization\n",
    "*   Basic filtering techniques\n",
    "\n",
    "<!-- ### **Remember this is a graded exercise.** -->\n",
    "\n",
    "**Reminder**:\n",
    "\n",
    "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
    "*   Add sufficient comments and explanations wherever necessary.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuqI1scQ4imT"
   },
   "outputs": [],
   "source": [
    "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data, exposure, filters, io, morphology, color"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OV5XxAg85xJ_"
   },
   "source": [
    "# Channels and color spaces\n",
    "\n",
    "### **Exercise: Image Creation and Color Manipulation**\n",
    "\n",
    "*   Create a 100 x 100 image for each of the below visualization\n",
    "\n",
    "\n",
    "*   Visualize the created images in a 1 x 3 subplot using matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvftuOlr5woU"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "image_1 = np.zeros((100, 100))\n",
    "image_1[:, 50:] = 1\n",
    "\n",
    "image_2 = np.zeros((100, 100))\n",
    "image_2[50:, :] = 1\n",
    "\n",
    "image_3 = np.zeros((100, 100))\n",
    "image_3[0:50, 0:50] = 1\n",
    "\n",
    "\n",
    "figs, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(image_1, cmap='gray')\n",
    "axes[0].set_title(\"Image 1- Left Black Right White\")\n",
    "axes[0].axis('on')\n",
    "\n",
    "axes[1].imshow(image_2, cmap='gray')\n",
    "axes[1].set_title(\"Image 2- Top Black Bottom White\")\n",
    "axes[1].axis('on')\n",
    "\n",
    "axes[2].imshow(image_3, cmap='gray')\n",
    "axes[2].set_title(\"Image 3 - Top Left Corner White and Rest Black\")\n",
    "axes[2].axis('on')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ52BL-WrWV-"
   },
   "source": [
    "*   Use the above three images to create the following image\n",
    "\n",
    "*Hint: Remember channels and color spaces*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjFNuJ4Rraiw"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "image = np.zeros((100, 100, 3))\n",
    "\n",
    "#Top-left: Blue\n",
    "image[:50, :50, 2] = 1 \n",
    "\n",
    "#Top-right: Red\n",
    "image[:50, 50:, 0] = 1\n",
    "\n",
    "#Bottom-left: Green\n",
    "image[50:, :50, 1] = 1  \n",
    "\n",
    "#Bottom-right: Yellow\n",
    "image[50:, 50:, 0] = 1  \n",
    "image[50:, 50:, 1] = 1 \n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Four Corners: Red, Blue, Green, Yellow\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e3jnTbnqIkN_"
   },
   "source": [
    "### **Exercise: Color Manipulation**\n",
    "\n",
    "*   Read the image 'sillas.jpg' from the images folder\n",
    "\n",
    "*   Extract individual channels and plot them using matplotlib subplot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6T8NHYIAJ7fr"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "sillas_image = io.imread('images/sillas.jpg')\n",
    "\n",
    "#Extract channels\n",
    "red_channel = sillas_image[:, :, 0]\n",
    "green_channel = sillas_image[:, :, 1]\n",
    "blue_channel = sillas_image[:, :, 2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "#Display the original image\n",
    "axes[0].imshow(sillas_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "#Display the Red channel\n",
    "axes[1].imshow(red_channel, cmap='Reds')\n",
    "axes[1].set_title(\"Red Channel\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "#Display the Green channel\n",
    "axes[2].imshow(green_channel, cmap='Greens')\n",
    "axes[2].set_title(\"Green Channel\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "#Display the Blue channel\n",
    "axes[3].imshow(blue_channel, cmap='Blues')\n",
    "axes[3].set_title(\"Blue Channel\")\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2KsIGB8shvy"
   },
   "source": [
    "*   The color **red** looks too bright for the eyes. Isn't it?? Lets change the color and see how it appears.\n",
    "    *    Create a new image where everything that is **'red' is changed to 'blue'**.\n",
    "*   Visualize the original image and the created image using matplotlib subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "111KEZossmpl"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "#Create a copy of the image to modify\n",
    "copy_image = np.copy(sillas_image)\n",
    "copy_image[:, :, 0] = blue_channel\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "#Original image\n",
    "axes[0].imshow(sillas_image)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "#Modified image\n",
    "axes[1].imshow(copy_image)\n",
    "axes[1].set_title(\"Modified Image (Red to Blue)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I7ILNRvsJ9fm"
   },
   "source": [
    "# Image Manipulation\n",
    "\n",
    "### **Exercise: Image Operators**\n",
    "\n",
    "*   You can find images 'model.png' and 'coat.png' in the images folder (First two images of the below visualization). Your task is to create an image from the given two images such a way that the model is wearing the coat (Third image in the visualization).\n",
    "*   You can also find different textures in the images folder. Your task is to change the coat texture to any one of the given textures.\n",
    "*   Visualize the images similar to the given visualization.\n",
    "\n",
    "*Hint: Think masks!!!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVfOvZnCH4pK"
   },
   "outputs": [],
   "source": [
    "model_image = io.imread('images/model.png')\n",
    "coat_image = io.imread('images/coat.png')\n",
    "texture_image = io.imread('images/texture.png')\n",
    "\n",
    "#Remove alpha channels if they exist\n",
    "if model_image.shape[2] == 4:\n",
    "    model_image = model_image[:, :, :3]  # Remove alpha channel if present\n",
    "if coat_image.shape[2] == 4:\n",
    "    coat_image = coat_image[:, :, :3]  # Remove alpha channel if present\n",
    "if texture_image.shape[2] == 4:\n",
    "    texture_image = texture_image[:, :, :3]  # Remove alpha channel if present\n",
    "\n",
    "#Resize coat and texture to match the model image\n",
    "coat_resize = cv.resize(coat_image, (model_image.shape[1], model_image.shape[0]))\n",
    "texture_resize = cv.resize(texture_image, (model_image.shape[1], model_image.shape[0]))\n",
    "\n",
    "#Create mask for the coat using grayscale\n",
    "gray_coat = cv.cvtColor(coat_resize, cv.COLOR_RGB2GRAY)\n",
    "_, mask = cv.threshold(gray_coat, 1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "#Expand the mask to 3 channels\n",
    "mask_3d = np.stack([mask] * 3, axis=-1)\n",
    "\n",
    "#Apply the coat on the model image\n",
    "model_with_coat = model_image.copy()\n",
    "model_with_coat[mask_3d == 255] = coat_resize[mask_3d == 255]\n",
    "\n",
    "#Apply the texture to the coat region (masked area)\n",
    "coat_with_texture = coat_resize.copy()\n",
    "coat_with_texture[mask == 255] = texture_resize[mask == 255]\n",
    "\n",
    "#Overlay the textured coat onto the model\n",
    "model_with_textured_coat = model_image.copy()\n",
    "model_with_textured_coat[mask_3d == 255] = coat_with_texture[mask_3d == 255]\n",
    "\n",
    "\n",
    "figs, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(coat_image)\n",
    "axes[0].set_title(\"Coat\")\n",
    "axes[0].axis('on')\n",
    "\n",
    "axes[1].imshow(model_image)\n",
    "axes[1].set_title(\"Model\")\n",
    "axes[1].axis('on')\n",
    "\n",
    "axes[2].imshow(model_with_yellow_coat)\n",
    "axes[2].set_title(\"Model with Coat\")\n",
    "axes[2].axis('on')\n",
    "\n",
    "axes[3].imshow(model_with_textured_coat)\n",
    "axes[3].set_title(\"Model with Textured Coat\")\n",
    "axes[3].axis('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTEmlIhY0w46"
   },
   "source": [
    "# Contrast Enhancement\n",
    "\n",
    "### **Exercise: Histogram Computation**\n",
    "\n",
    "*   Read the **'astronaut' image** from data module.\n",
    "*   Convert the image to grayscale.\n",
    "*   Compute the **histogram of the image.** *Hint: histogram function is available in skimage.exposure package*\n",
    "*   Plot the histogram using matplotlib plot.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkh-HIjW2SBW"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "astronaut_image = data.astronaut()\n",
    "\n",
    "#Grayscale\n",
    "grayscale_astronaut = color.rgb2gray(astronaut_image)\n",
    "\n",
    "hist, bin_centers = exposure.histogram(grayscale_astronaut)\n",
    "\n",
    "#Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bin_centers, hist, lw=2)\n",
    "plt.title('Histogram of Grayscale Astronaut Image')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIeB6eUYs-lR"
   },
   "source": [
    "*   Change the bin count to 8 and compute the histogram of the image and plot the computed histogram using matplotlib plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXxj9_ZptB0_"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "#Compute the histogram with 8 bins\n",
    "hist, bin_centers = exposure.histogram(grayscale_astronaut, nbins=8)\n",
    "\n",
    "#Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_centers, hist, width=0.1, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Grayscale Astronaut Image (8 bins)')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyBcGEtEJXP_"
   },
   "source": [
    "\n",
    "\n",
    "*   What happens when you change the bin count? Does your inference change based on the bin count? If yes, then how do you define the correct bin count.\n",
    "*   What happens when the bin count is very low and what happens when it is very high?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw8L1ZKvKOvo"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "Changing the bin count in a histogram affects how the data is grouped and visualized. A low bin count (e.g., 8 bins) makes the histogram coarser, losing detailed variations in pixel intensities, but provides a rough overview of the distribution. This can be useful for general trends, but finer details may be missed. A high bin count (e.g., 256 or more) captures more detailed variations, revealing subtle differences in pixel intensity, but can lead to overfitting by emphasizing noise and making the histogram harder to interpret. In other words, too few bins may oversimplify the data, while too many can complicate interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecOWgER2U_n"
   },
   "source": [
    "\n",
    "*   Compute histogram of the color image (without converting it to grayscale).\n",
    "*   Plot the total histogram and also histogram for each channel (show it in a single plot with differnt legends for each histogram).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R425Nve2Til"
   },
   "outputs": [],
   "source": [
    "#solution\n",
    "astronaut_image = data.astronaut()\n",
    "\n",
    "#Split the image into Red, Green, and Blue channels\n",
    "red_channel = astronaut_image[:, :, 0]  # Red channel\n",
    "green_channel = astronaut_image[:, :, 1]  # Green channel\n",
    "blue_channel = astronaut_image[:, :, 2]  # Blue channel\n",
    "\n",
    "#Compute histograms for each channel\n",
    "hist_red, bin_centers_red = exposure.histogram(red_channel)\n",
    "hist_green, bin_centers_green = exposure.histogram(green_channel)\n",
    "hist_blue, bin_centers_blue = exposure.histogram(blue_channel)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(bin_centers_red, hist_red, color='red', label='Red Channel', lw=2)\n",
    "plt.plot(bin_centers_green, hist_green, color='green', label='Green Channel', lw=2)\n",
    "plt.plot(bin_centers_blue, hist_blue, color='blue', label='Blue Channel', lw=2)\n",
    "\n",
    "# Plot histogram\n",
    "total_hist = hist_red + hist_green + hist_blue\n",
    "plt.plot(bin_centers_red, total_hist, color='black', label='Total Histogram', lw=2, linestyle='--')\n",
    "plt.title('Histogram of Color Image and Each Channel')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr9af6my4uKv"
   },
   "source": [
    "### **Exercise: Histogram Equalization**\n",
    "\n",
    "*   Read 'aquatermi_lowcontrast.jpg' image from the images folder.\n",
    "*   Compute the histogram of the image.\n",
    "*   Perform histogram equalization of the image to enhance the contrast. *Hint: Use equalize_hist function available in skimage.exposure*\n",
    "*   Also compute histogram of the equalized image.\n",
    "*   Use 2 x 2 subplot to show the original image and the enhanced image along with the corresponding histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ROMuC8F6IYf"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "aquatermi_image = io.imread('images/aquatermi_lowcontrast.jpg')\n",
    "\n",
    "#Compute the histogram of the original image\n",
    "hist_original, bin_centers_original = exposure.histogram(aquatermi_image)\n",
    "\n",
    "#Perform histogram equalization\n",
    "equalized_image = exposure.equalize_hist(aquatermi_image)\n",
    "\n",
    "#Compute the histogram of the equalized image\n",
    "hist_equalized, bin_centers_equalized = exposure.histogram(equalized_image)\n",
    "\n",
    "#Create 2x2 subplot for displaying the images and histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "#Display original image\n",
    "axes[0, 0].imshow(aquatermi_image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "#Display histogram of the original image\n",
    "axes[0, 1].plot(bin_centers_original, hist_original, color='black')\n",
    "axes[0, 1].set_title('Histogram of Original Image')\n",
    "axes[0, 1].set_xlabel('Pixel Intensity')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "#Display equalized image\n",
    "axes[1, 0].imshow(equalized_image, cmap='gray')\n",
    "axes[1, 0].set_title('Equalized Image')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "#Display histogram of the equalized image\n",
    "axes[1, 1].plot(bin_centers_equalized, hist_equalized, color='black')\n",
    "axes[1, 1].set_title('Histogram of Equalized Image')\n",
    "axes[1, 1].set_xlabel('Pixel Intensity')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvDnkRKA8PXe"
   },
   "source": [
    "\n",
    "*   The above function in skimage.exposure uses cdf and interpolation technique to normalize the histogram. How is it different from linear contrast stretch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOCa3PzJLhl0"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "Histogram equalization and linear contrast stretching both enhance image contrast but differ in their approaches. Histogram equalization redistributes pixel intensities to achieve a more uniform histogram, enhancing contrast non-linearly across the image. This can lead to over-enhancement in well-contrasted areas. On the other hand, linear contrast stretching maps pixel intensities between the minimum and maximum values, providing a simple, linear contrast boost. While histogram equalization adapts to the image's distribution, linear contrast stretching offers a more predictable and controlled enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boFCTwGV8kaz"
   },
   "source": [
    "### **Exercise: Linear Contrast Stretch**\n",
    "\n",
    "*   Write a function to compute the linear contrast stretch (Do not use an inbuilt function). \n",
    "*   Provide grayscale image array and bin count as parameters to the function and return the enhanced image array.\n",
    "*   Use a 2 x 2 plot to visualize the original image, histogram, enhanced image and the corresponding histogram.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6mlhI_s8lLv"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "#Function to perform linear contrast stretch\n",
    "def linear_contrast_stretch(image, bin_count=256):\n",
    "    #Find the minimum and maximum pixel values in the image\n",
    "    I_min = np.min(image)\n",
    "    I_max = np.max(image)\n",
    "    \n",
    "    #Apply linear contrast stretching formula\n",
    "    enhanced_image = ((image - I_min) / (I_max - I_min) * 255).astype(np.uint8)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "#Read a grayscale image (use an example)\n",
    "image = io.imread('images/aquatermi_lowcontrast.jpg')\n",
    "if image.ndim == 3:\n",
    "    image = np.mean(image, axis=2)\n",
    "\n",
    "#Perform linear contrast stretch\n",
    "enhanced_image = linear_contrast_stretch(image)\n",
    "\n",
    "#Compute histograms\n",
    "hist_original, bin_centers = exposure.histogram(image, nbins=256)\n",
    "hist_enhanced, _ = exposure.histogram(enhanced_image, nbins=256)\n",
    "\n",
    "#Create 2x2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "#Plot original image\n",
    "axes[0, 0].imshow(image, cmap='gray')\n",
    "axes[0, 0].set_title(\"Original Image\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "#Plot histogram of original image\n",
    "axes[0, 1].plot(bin_centers, hist_original, color='black')\n",
    "axes[0, 1].set_title(\"Original Histogram\")\n",
    "axes[0, 1].set_xlabel(\"Pixel Intensity\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "#Plot enhanced image\n",
    "axes[1, 0].imshow(enhanced_image, cmap='gray')\n",
    "axes[1, 0].set_title(\"Enhanced Image\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "#Plot histogram of enhanced image\n",
    "axes[1, 1].plot(bin_centers, hist_enhanced, color='black')\n",
    "axes[1, 1].set_title(\"Enhanced Histogram\")\n",
    "axes[1, 1].set_xlabel(\"Pixel Intensity\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfuWqX2BWyXm"
   },
   "source": [
    "# Filters\n",
    "\n",
    "### **Exercise: Mean Filter**\n",
    "\n",
    "*   Load the **coins** image from the data module.\n",
    "*   Define a disk structuring element (selem) of radius 20. *Hint: Structuring elements are defined in the skimage.morphology module*\n",
    "*   Use mean filter using the created selem. *Hint: The mean filter is available in skimage.filters.rank module*\n",
    "*   Increase the radius of the selem by 10 and apply the mean filter.\n",
    "*   Reduce the radius of the selem by 10 and apply the mean filter.\n",
    "*   Visualize all the smoothened images along with the original image.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qp7_zxDjL7vS"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "coins_image = data.coins()\n",
    "\n",
    "#Define a disk structuring element with radius 20\n",
    "selem_20 = morphology.disk(20)\n",
    "\n",
    "#Apply mean filter with radius 20\n",
    "smoothed_20 = filters.rank.mean(coins_image, selem_20)\n",
    "\n",
    "#Increase radius of the structuring element by 10 (radius 30)\n",
    "selem_30 = morphology.disk(30)\n",
    "\n",
    "#Apply mean filter with radius 30\n",
    "smoothed_30 = filters.rank.mean(coins_image, selem_30)\n",
    "\n",
    "#Reduce radius of the structuring element by 10 (radius 10)\n",
    "selem_10 = morphology.disk(10)\n",
    "\n",
    "# Apply mean filter with radius 10\n",
    "smoothed_10 = filters.rank.mean(coins_image, selem_10)\n",
    "\n",
    "#Plot images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "#Display original image\n",
    "axes[0, 0].imshow(coins_image, cmap='gray')\n",
    "axes[0, 0].set_title(\"Original Image\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "#Display smoothed image with radius 20\n",
    "axes[0, 1].imshow(smoothed_20, cmap='gray')\n",
    "axes[0, 1].set_title(\"Smoothed Image (Radius 20)\")\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "#Display smoothed image with radius 30\n",
    "axes[1, 0].imshow(smoothed_30, cmap='gray')\n",
    "axes[1, 0].set_title(\"Smoothed Image (Radius 30)\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "#Display smoothed image with radius 10\n",
    "axes[1, 1].imshow(smoothed_10, cmap='gray')\n",
    "axes[1, 1].set_title(\"Smoothed Image (Radius 10)\")\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DIOQCcsvEqG"
   },
   "source": [
    "*   Use different selem (square, rectangle, star, diamond) to view the behaviour of the mean filter (It is not necessary to repeat with different sizes; it is sufficient to show the one with optimal parameter).\n",
    "*   Create a 2 x n subplot to show the selem in the first row and the corresponding smoothened image in the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GbQXmYvvXUO"
   },
   "outputs": [],
   "source": [
    "# solution\n",
    "coins_image = data.coins()\n",
    "\n",
    "#Define different structuring elements\n",
    "selem_square = morphology.square(20)  # Square with side 20\n",
    "selem_rectangle = morphology.rectangle(20, 40)  # Rectangle with dimensions 20x40\n",
    "selem_star = morphology.star(20)  # Star with radius 20\n",
    "selem_diamond = morphology.diamond(20)  # Diamond with radius 20\n",
    "\n",
    "#Apply mean filter with each structuring element\n",
    "smoothed_square = filters.rank.mean(coins_image, selem_square)\n",
    "smoothed_rectangle = filters.rank.mean(coins_image, selem_rectangle)\n",
    "smoothed_star = filters.rank.mean(coins_image, selem_star)\n",
    "smoothed_diamond = filters.rank.mean(coins_image, selem_diamond)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "#Display structuring elements and corresponding smoothed images\n",
    "axes[0, 0].imshow(selem_square, cmap='gray')\n",
    "axes[0, 0].set_title(\"Square SELEM\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(selem_rectangle, cmap='gray')\n",
    "axes[0, 1].set_title(\"Rectangle SELEM\")\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(selem_star, cmap='gray')\n",
    "axes[0, 2].set_title(\"Star SELEM\")\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[0, 3].imshow(selem_diamond, cmap='gray')\n",
    "axes[0, 3].set_title(\"Diamond SELEM\")\n",
    "axes[0, 3].axis('off')\n",
    "\n",
    "# Row 2: Show the smoothed images\n",
    "axes[1, 0].imshow(smoothed_square, cmap='gray')\n",
    "axes[1, 0].set_title(\"Smoothed (Square SELEM)\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(smoothed_rectangle, cmap='gray')\n",
    "axes[1, 1].set_title(\"Smoothed (Rectangle SELEM)\")\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(smoothed_star, cmap='gray')\n",
    "axes[1, 2].set_title(\"Smoothed (Star SELEM)\")\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(smoothed_diamond, cmap='gray')\n",
    "axes[1, 3].set_title(\"Smoothed (Diamond SELEM)\")\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV7OHQwKZ9GU"
   },
   "source": [
    "*   How does changing the radius of disk affect the smoothing functionality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG91LBzwMBUR"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "By changing the radius of the disk structuring element, or selem, it directly affects the extent of smoothing applied to the image. A larger radius includes more neighboring pixels in the mean calculation, resulting in stronger smoothing and a blurrier image. Conversely, a smaller radius focuses on fewer neighboring pixels, leading to a less pronounced smoothing effect, maintaining more detail. That is to say that increasing the radius smooths the image more, while decreasing it preserves finer details but reduces the level of smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPJFLYMkMBqs"
   },
   "source": [
    "\n",
    "*   What is the observed behaviour with difference in the structuring element?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcJkpvnjMFY5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "The choice of structuring element (selem) significantly impacts the smoothing behavior.\n",
    "\n",
    "- Square: Provides uniform smoothing in all directions, creating a balanced blur with no directional preference.\n",
    "- Rectangle: Smooths more in the direction of the longer side, leading to a less uniform blur, often preserving detail along the shorter side.\n",
    "- Star: Offers a more localized smoothing effect with a focus on pixels within the radius, preserving edges and details more than the square and rectangle in some areas.\n",
    "- Diamond: Similar to the star, but with a more angular smoothing pattern, affecting pixel neighborhoods differently, leading to less uniform smoothing near the edges.\n",
    "  \n",
    "In general, the shape and orientation of the structuring element influence how the filter smooths the image, with rectangular and star shapes often introducing directional smoothing effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hySxTKM4AB"
   },
   "source": [
    "\n",
    "\n",
    "*   What is the difference between mean filter and gaussian filter?\n",
    "*   Where do you use mean filters and where do you use gaussian filters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0foSx_GNDB5"
   },
   "source": [
    "**Solution**\n",
    "\n",
    "A mean filter is a simple averaging filter that replaces each pixel's value with the average of its neighboring pixels, offering uniform smoothing. It's effective for removing salt-and-pepper noise but can blur edges and details. A Gaussian filter uses a weighted average where pixels closer to the center of the kernel have higher weights, following a Gaussian distribution. This filter provides smoother results while better preserving edges, making it ideal for reducing Gaussian noise and for applications where edge preservation is crucial, such as image preprocessing in object detection or segmentation. While mean filters are useful in scenarios with uniform noise, Gaussian filters are preferred when maintaining detail and smoothness without sacrificing edge clarity is important."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPs+7OmQKl06bCVLggAj4BU",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
